<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Databases | chapter31 &raquo;]]></title>
  <link href="http://chapter31.github.io/categories/databases/atom.xml" rel="self"/>
  <link href="http://chapter31.github.io/"/>
  <updated>2013-04-27T22:42:07+10:00</updated>
  <id>http://chapter31.github.io/</id>
  <author>
    <name><![CDATA[Michael Sharman]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Concatenating values into a single column with MySQL group_concat]]></title>
    <link href="http://chapter31.github.io/2012/07/06/concatenating-values-into-a-single-column-with-mysql-group_concat/"/>
    <updated>2012-07-06T07:15:31+10:00</updated>
    <id>http://chapter31.github.io/2012/07/06/concatenating-values-into-a-single-column-with-mysql-group_concat</id>
    <content type="html"><![CDATA[<p>How many times have you wanted to return a list of grouped values from a database, in a single column, per row of your recordset? Actually I've wanted to do that a few times! Most of the time I'll let the application layer handle that, but sometimes letting the database do the hard work fits the bill.</p>

<p>My not-so-theoretical example is <em>course subjects</em> (think English, Maths etc) that have 1-<em>n</em> "stages" (think categories) attached to them. If I want to return a recordset of all courses, with the attached stages, I might write a query like this:</p>

<p><code>sql
SELECT sy.title as course, st.stage
FROM syllabus sy INNER JOIN syllabus_stages sy_st
ON sy.id = sy_st.syllabus_id
INNER JOIN stages st
ON sy_st.stage_id = st.id
GROUP BY sy.title, stage
ORDER BY sy.title
</code></p>

<p>Looks pretty standard, with something like that I'd get the following:</p>

<p><img src="http://www.chapter31.com/wp-content/uploads/2012/07/Screen-shot-2012-07-06-at-6.50.45-AM.png" alt="" /></p>

<p>But now the application has to handle the grouping, not a huge problem by any means. Also don't get me wrong...this is where you normally would want to do this (sql is a data retrieval language and in most instances shouldn't be handling presentation aspects). However, if I just wanted to display a list of stages (categories), I can use <a href="http://dev.mysql.com/doc/refman/5.0/en/group-by-functions.html#function_group-concat">group_concat</a> to make life a litte easier.</p>

<p><code>sql
SELECT sy.title as course, group_concat(st.stage ORDER BY st.stage) as stage
FROM syllabus sy INNER JOIN syllabus_stages sy_st
ON sy.id = sy_st.syllabus_id
INNER JOIN stages st
ON sy_st.stage_id = st.id
GROUP BY sy.title
ORDER BY sy.title
</code></p>

<p>This gives me:</p>

<p><img src="http://www.chapter31.com/wp-content/uploads/2012/07/Screen-shot-2012-07-06-at-6.53.14-AM.png" alt="" /></p>

<p>Pretty cool eh?</p>

<p>The default list separator is a comma, but you can also specify your own.</p>

<p><code>sql
SELECT sy.title as course, group_concat(st.stage ORDER BY st.stage SEPARATOR ' | ') as stage
FROM syllabus sy INNER JOIN syllabus_stages sy_st
ON sy.id = sy_st.syllabus_id
INNER JOIN stages st
ON sy_st.stage_id = st.id
GROUP BY sy.title
ORDER BY sy.title
</code></p>

<p><img src="http://www.chapter31.com/wp-content/uploads/2012/07/Screen-shot-2012-07-06-at-7.12.02-AM.png" alt="" /></p>

<p><a href="http://dev.mysql.com/doc/refman/5.0/en/group-by-functions.html#function_group-concat">See the group_concat page</a> for more details.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Error restoring MySQL database when USING BTREE on indexes]]></title>
    <link href="http://chapter31.github.io/2012/03/15/error-restoring-mysql-database-when-using-btree-on-indexes/"/>
    <updated>2012-03-15T15:42:39+11:00</updated>
    <id>http://chapter31.github.io/2012/03/15/error-restoring-mysql-database-when-using-btree-on-indexes</id>
    <content type="html"><![CDATA[<p>Occasionally when I'm restoring a database that was backed up from a different server than the one I'm restoring on I get an error along the lines of:</p>

<p>``` javascript</p>

<blockquote><p>[Error] Script lines: 5-17 -------------------------
 You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8' at line 11</p></blockquote>

<p> Warnings: --->
   W (1): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8' at line 11
```</p>

<p>Hmm, the docs suggest that BTREE is a valid index type for both MyISAM and InnoDB. So why is it barfing?</p>

<p>Well it turns out dumping the database from a newer version of MySQL than what you are restoring onto can be bad. In my case running status at the mysql prompt told me that my source database was running on <em>5.5.9</em> but the destination version was <em>5.0.51a</em>.</p>

<p>Basically the issue seems to be that MySQL 5.0.x has issues with USING BTREE. So...just remove that from your sql and you'll be good to go. Alternatively you can use the --compatible option when running your mysqldump on the <em>newer server version</em>, something like:</p>

<p><code>javascript
mysqldump --compatible=ansi -h127.0.0.1 -umyuser -p mydatabase | gzip &gt; mydatabase.sql.gz
</code></p>

<p>The value of "compatible" can be ansi, mysql323, mysql40, postgresql, oracle, mssql, db2, maxdb, no_key_options, no_table_options, or no_field_options.</p>

<p>Nice</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MySQL alternative to MSSQL's isNull() ]]></title>
    <link href="http://chapter31.github.io/2011/03/04/mysql-alternative-to-mssqls-isnull/"/>
    <updated>2011-03-04T10:22:53+11:00</updated>
    <id>http://chapter31.github.io/2011/03/04/mysql-alternative-to-mssqls-isnull</id>
    <content type="html"><![CDATA[<p>I was looking for a way to do isNull() in MySQL the other day, for those that don't know this means you can do something like:</p>

<p><code>javascript
SELECT isNull(mycolumn, 'blah') FROM myTable;
</code></p>

<p>If the value in <em>mycolumn</em> is NULL, then 'blah' is returned, this can of course be any string literal/numeric value you want. MySQL doesn't have isNull() but it does have <a href="http://dev.mysql.com/doc/refman/5.0/en/control-flow-functions.html#function_ifnull">ifNull()</a> which is basically the same.</p>

<p><code>javascript
SELECT ifNull(mycolumn, 'blah') FROM myTable;
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SQL for finding duplicate values]]></title>
    <link href="http://chapter31.github.io/2011/02/08/sql-for-finding-duplicate-values/"/>
    <updated>2011-02-08T17:47:18+11:00</updated>
    <id>http://chapter31.github.io/2011/02/08/sql-for-finding-duplicate-values</id>
    <content type="html"><![CDATA[<p>Quick post to remind me how to check a table column for duplicate values next time I'm looking for it (when my memory fails!)</p>

<p><code>javascript
SELECT id, count(id)
FROM mytable
GROUP BY id
HAVING count(id) &gt; 1
</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Importing a csv into MySQL using the command line]]></title>
    <link href="http://chapter31.github.io/2010/11/15/importing-a-csv-into-mysql-using-the-command-line/"/>
    <updated>2010-11-15T10:38:10+11:00</updated>
    <id>http://chapter31.github.io/2010/11/15/importing-a-csv-into-mysql-using-the-command-line</id>
    <content type="html"><![CDATA[<p><strong><em>UPDATE 16th Nov 2010: I had some issues with the import which I noted in the first code example below</em></strong></p>

<p>Today I had to import csv into a single mysql table. The destination table only had 5 columns and the csv was around 22MB (around 400,000 records). The csv also contained more columns that I needed for the import. Sometimes I'll use a GUI to do this as I usually have one open, but it never ceases to amaze me how much slower GUI tools are compared to the command line.</p>

<p>To import the file via Aqua Data Studio took around 20 mins to import on my machine (over the network to the staging server took over 40mins!). As I need to do this more and more I though I'd look at a few command line options. I actually wanted to do this in 2 steps; firstly import the csv, them export it as a sql file and import it into "production" from there.</p>

<p>First we need to import the original .csv, ignoring certrain columns which the destination table didn't need. Why not open this in excel/open office and <code>clean</code> the csv first? Too many rows, by default open office won't read that many rows, plus it slows the machine down to even try that, double plus it's super simple to ignore columns you don't need:</p>

<p>``` javascript
mysql> LOAD DATA LOCAL INFILE '/pathtofile/myfile.csv'</p>

<pre><code>-&gt; INTO TABLE MyTable
-&gt; FIELDS TERMINATED BY ',' 
-&gt; ENCLOSED BY '"'
-&gt; LINES TERMINATED BY '\r\n' 
-&gt; (col1,col2,@ignore,col3,col4,@ignore,col5);
</code></pre>

<p>```</p>

<p>Note the LINES TERMINATED BY...you really need '\r\n', especially if you .csv had been generated from a Windows machine! Otherwise your import will be kinda funky :(</p>

<p>Also note the ENCLOSED BY '"', if you skip that option then any data in the .csv what was enclosed by double quotes (strings for eg) will actually import the double quotes into your database which is more than likely not what you want.</p>

<p>Note the <code>@ignore</code> user variables specified in the column list. Basically that's saying that there are extra columns in the csv which I don't want to import into the database. So by assigning the csv column to a user variable and not assigning the variable to an actual table column you effectively ignore it. You can call the user variable anything you want (prefixed with <code>@</code> of course). Calling it <code>@ignore</code> made sense to me.</p>

<p>Great now we have our data in the table, took about 2 seconds to run as opposed to 20min in the GUI tool :/</p>

<p>Then I had to quickly massage the data via sql as defined by the business rules as the original csv was <code>incomplete</code> in terms of the application requirements. After that was done I exported the table into a sql file:</p>

<p><code>javascript
mysqldump -uroot -p [local_database_name] [table_to_export] --skip-opt --compact --disable-keys --extended-insert --no-create-info &gt; mytable.sql
</code></p>

<p>The options used here skip things in the .sql file like CREATE TABLE etc. They also combine INSERTS and disable the keys to improve the speed of the import. Finally import the production ready sql into:</p>

<p><code>javascript
mysql -uroot -p [production_database] &lt; mytable.sql
</code></p>

<p>Again, the point of this is pure performance. The speed difference is incredible, even on a local machine I don't know why anyone would bother using GUI tools to import/export data unless you were working with tiny databases/tables.</p>
]]></content>
  </entry>
  
</feed>
